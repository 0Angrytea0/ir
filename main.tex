\documentclass[12pt,a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[russian]{babel}

\usepackage{geometry}
\geometry{left=25mm,right=15mm,top=20mm,bottom=20mm}

\usepackage{graphicx}
\usepackage{float}
\usepackage{tabularx}
\usepackage{longtable}
\usepackage{amsmath}
\usepackage{hyperref}
\hypersetup{colorlinks=true,linkcolor=black,urlcolor=blue,citecolor=black}

\begin{document}

\begin{titlepage}
\begin{center}
\textbf{Московский авиационный институт (национальный исследовательский университет)}\\[6mm]
Институт информационных технологий и прикладной математики\\
«Кафедра вычислительной математики и программирования»\\[22mm]
\textbf{\Large Отчёт по лабораторным работам по курсу}\\[2mm]
\textbf{\Large «Информационный поиск» IV курс, VII семестр}\\[3mm]
\end{center}

\vspace{8mm}

\noindent
\begin{tabularx}{\textwidth}{@{}lX@{}}
\textbf{Студентка:} & Соколова В.Д.\\[2mm]
\textbf{Преподаватель:} & Кухтичев А.А.\\[2mm]
\textbf{Группа:} & М8О-401Б-22\\[2mm]
\textbf{Дата:} & 28.12.2025\\[2mm]
\textbf{Оценка:} & \rule{60mm}{0.4pt}\\[2mm]
\textbf{Подпись:} & \rule{60mm}{0.4pt}\\
\end{tabularx}

\vfill
\begin{center}
Москва 2025 г.
\end{center}
\end{titlepage}

\tableofcontents
\newpage

\section{Введение}
Целью работы является построение учебной поисковой системы по собственному корпусу документов: от добычи корпуса и хранения «сырых» документов до токенизации, стемминга, анализа частот терминов и реализации булевого индекса и булевого поиска (CLI и Web). Реализованный пайплайн обеспечивает воспроизводимую обработку документов: сбор, извлечение текста, нормализация, построение индекса и выполнение булевых запросов.

\section{Лабораторная работа №1. Добыча корпуса документов}

\subsection{Источник данных}
Корпус сформирован из двух независимых источников на движке MediaWiki:
\begin{itemize}
  \item Русская Википедия: \texttt{https://ru.wikipedia.org/w/api.php}.
  \item Русская Викитека: \texttt{https://ru.wikisource.org/w/api.php}.
\end{itemize}

\subsection{Характеристики документов и мета-информация}
Для каждого документа сохраняются:
\begin{itemize}
  \item «сырой» документ в формате HTML, полученный через \texttt{action=parse, prop=text};
  \item выделенный текст в виде плоского текста (без вики-разметки), полученный через \texttt{prop=extracts, explaintext=1};
  \item мета-информация: \texttt{doc\_id}, \texttt{page\_id}, \texttt{title}, \texttt{source}, а также имена файлов raw/text.
\end{itemize}

Дополнительно для выделенного текста применяется обрезка хвостовых разделов («Ссылки», «Примечания», «Литература», «Внешние ссылки»), что снижает долю шумовых фрагментов в дальнейшей индексации.

\subsection{Выделение текста}
Выделенный текст получен средствами MediaWiki API (\texttt{extracts}) и приведён к единому виду: UTF-8, без HTML и без вики-разметки, с минимальной эвристической очисткой хвостовых разделов. Такой текст используется как вход для токенизации и последующих лабораторных работ.

\subsection{Готовые поисковики и примеры запросов}
Для обоих источников существует готовый поиск:
\begin{itemize}
  \item встроенный поиск на сайтах Википедии и Викитеки;
  \item поиск Google с ограничением по домену: \texttt{site:ru.wikipedia.org} и \texttt{site:ru.wikisource.org}.
\end{itemize}

Примеры запросов и характерные недостатки выдачи:
\begin{itemize}
  \item \texttt{site:ru.wikipedia.org фильм триллер 1999} — в выдаче нередко доминируют страницы-списки, категории и навигационные страницы, а не конкретные статьи.
  \item \texttt{site:ru.wikisource.org стихотворение осень} — встречаются оглавления, страницы категорий и служебные страницы, что снижает точность полнотекстового поиска.
  \item \texttt{site:ru.wikipedia.org режиссер снял фильм} — результаты содержат шум из шаблонов и повторяющихся блоков, а также страдают от разной морфологии слов без учёта словоформ.
\end{itemize}

\subsection{Статистика корпуса}
Корпус содержит 37\,420 документов. Для оценки длины документов использована выборка из 2000 документов; длина измерялась как число символов в выделенном тексте. Получены следующие значения:
\begin{itemize}
  \item минимальная длина: 263;
  \item медиана: 2066;
  \item средняя длина: 3648;
  \item максимальная длина: 77221.
\end{itemize}

Статистика по «сырым» документам (HTML) оценивается отдельно по размеру сохранённых raw-файлов; выделенный текст имеет меньший объём за счёт отсутствия разметки и служебных блоков.

\section{Лабораторная работа №2. Поисковый робот}

\subsection{Требования и формат конфигурации}
Поисковый робот реализован как консольная программа, которой передаётся единственный аргумент: путь до \texttt{YAML}-конфига. Конфиг содержит:
\begin{itemize}
  \item секцию \texttt{db} с параметрами подключения к базе данных;
  \item секцию \texttt{logic} с параметрами робота, включая задержку между запросами;
  \item секцию источников (\texttt{sources}), содержащую данные MediaWiki (endpoint API, категории/стартовые точки).
\end{itemize}

\subsection{Схема хранения в базе данных}
Робот сохраняет документы в базе данных со следующими полями:
\begin{itemize}
  \item \texttt{url} — нормализованный URL документа;
  \item \texttt{html} — «сырой» HTML-текст документа;
  \item \texttt{source} — название источника;
  \item \texttt{fetch\_ts} — дата обкачки в формате Unix timestamp;
  \item \texttt{hash} — контрольная сумма содержимого (для проверки изменений).
\end{itemize}

\subsection{Нормализация URL}
Для MediaWiki-страниц URL приводится к единому виду \texttt{https://<host>/?curid=<page\_id>} без лишних параметров. Это обеспечивает устойчивое совпадение ключа документа в БД и корректность дедупликации.

\subsection{Продолжение после остановки}
Состояние робота хранится в отдельной записи (\texttt{state}), включающей курсор обхода (позицию/continue-token). При повторном запуске робот читает состояние и продолжает обкачку с последнего сохранённого документа без повторной загрузки уже обработанных элементов.

\subsection{Переобкачка и обновление только при изменениях}
Для переобкачки используется сравнение контрольной суммы \texttt{hash}. Документ переобкачивается по расписанию, но запись обновляется только если новая контрольная сумма отличается от сохранённой. Это снижает нагрузку на источник и объём лишних операций записи в БД.

\section{Лабораторная работа №3. Токенизация}

\subsection{Правила токенизации}
Токенизация реализована для входного текста в UTF-8. Токеном считается максимальная последовательность символов из множества:
\begin{itemize}
  \item кириллица (включая Ё/ё);
  \item латиница;
  \item цифры.
\end{itemize}
Все буквенные символы приводятся к нижнему регистру. Любые символы вне указанного множества являются разделителями токенов. Результат сохраняется в файлы \texttt{*.tok} (один токен на строку).

\subsection{Достоинства и недостатки}
Достоинства:
\begin{itemize}
  \item линейная сложность по объёму входных данных;
  \item одинаковые правила для разных источников;
  \item устойчивость к «грязному» тексту и случайным символам.
\end{itemize}

Недостатки:
\begin{itemize}
  \item токены с внутренними символами (\texttt{C++}, \texttt{e-mail}) дробятся;
  \item дефисные конструкции («С.-Петербург») распадаются на части;
  \item отдельные числовые и буквенно-числовые шаблоны требуют отдельных правил, если нужна повышенная точность.
\end{itemize}

\subsection{Статистические данные и производительность}
Для токенизации собираются:
\begin{itemize}
  \item количество токенов;
  \item средняя длина токена.
\end{itemize}

Время выполнения измеряется на уровне всего корпуса. Скорость токенизации рассчитывается как число килобайт входного текста, обработанных за секунду:
\[
V = \frac{\text{bytes\_in}/1024}{T}.
\]
Для ускорения токенизации применимы: потоковая обработка без чтения файла целиком в память, переиспользование буферов, параллельная обработка файлов и уменьшение количества аллокаций.

\section{Лабораторная работа №4. Лемматизация / стемминг}

\subsection{Метод нормализации словоформ}
В систему добавлен стемминг русского языка, выполняемый над токенами в UTF-8. Применены правила:
\begin{itemize}
  \item токены с цифрами не стеммятся;
  \item токены без кириллицы не стеммятся;
  \item задаётся минимальная длина основы, предотвращающая чрезмерную обрезку;
  \item снимаются типовые русские окончания и возвратность («ся/сь») по списку суффиксов.
\end{itemize}

\subsection{Место применения стемминга}
Стемминг применяется на этапе индексации и на этапе выполнения запроса:
\begin{itemize}
  \item индекс строится по стеммированным токенам, что увеличивает полноту;
  \item термы запроса приводятся к нижнему регистру и стеммируются теми же правилами, что обеспечивает совпадение с индексом.
\end{itemize}

\subsection{Оценка влияния на качество поиска}
Стемминг улучшает качество поиска на запросах с разными словоформами (рост полноты), например: «фильм/фильмы/фильма», «режиссёр/режиссёра/режиссёры». Ухудшения возможны из-за слияния разных слов в одну основу при агрессивной обрезке окончаний, а также на коротких словах и именах собственных. Снижение таких ошибок достигается повышением минимальной длины основы, ограничением набора снимаемых окончаний и комбинированием точного совпадения со стеммингом.

\section{Лабораторная работа №5. Закон Ципфа}

\subsection{Построение распределения частот}
По токенизированному корпусу построено распределение частот терминов. Термины отсортированы по убыванию частоты, каждому термину назначен ранг \(r\), и построен график в логарифмических шкалах \(\log f(r)\) от \(\log r\).

\subsection{Наложение закона Ципфа}
Использована модель Ципфа:
\[
f(r)=\frac{C}{r^s}.
\]
Коэффициент \(C\) выбран по частоте термина ранга 1, параметр \(s\) принят близким к 1. Наложение закона выполнено на график распределения частот терминов.

\subsection{Причины расхождений}
Расхождения с идеальной моделью объясняются:
\begin{itemize}
  \item предметной спецификой корпуса и неоднородностью тем;
  \item наличием часто повторяющихся служебных фрагментов и шаблонов;
  \item влиянием нормализации: стемминг объединяет словоформы, увеличивая частоты «основ»;
  \item ограниченностью корпуса по категориям и неслучайностью выборки документов.
\end{itemize}

\subsection{Графики}
\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{zipf_raw.png}
\caption{Распределение частот терминов и закон Ципфа (без стемминга), логарифмические шкалы.}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{zipf_stem.png}
\caption{Распределение частот терминов и закон Ципфа (со стеммингом), логарифмические шкалы.}
\end{figure}

\section{Лабораторная работа №6. Булев индекс}

\subsection{Постановка}
Реализован булев индекс (инвертированный индекс) для выполнения операций AND/OR/NOT по термам. Индекс строится по токенам (включая стеммированную версию) и хранит для каждого термина список идентификаторов документов, в которых он присутствует.

\subsection{Формат индекса}
Индекс сохранён в бинарном файле \texttt{index.bin}, содержащем:
\begin{itemize}
  \item заголовок с версией, флагами и смещениями секций;
  \item словарь терминов (терм, смещение postings, длина postings);
  \item секцию postings (последовательности \texttt{doc\_id});
  \item секцию документов с метаданными: \texttt{doc\_id}, \texttt{page\_id}, \texttt{title}, \texttt{source}.
\end{itemize}

\subsection{Учёт двух источников}
В метаданных документа сохранён \texttt{source}. Это используется в поиске для формирования корректного URL:
\begin{itemize}
  \item \texttt{ruwiki}: \texttt{https://ru.wikipedia.org/?curid=<page\_id>};
  \item \texttt{ru\_wikisource}: \texttt{https://ru.wikisource.org/?curid=<page\_id>}.
\end{itemize}

\section{Лабораторная работа №7. Булев поиск}

\subsection{Синтаксис запросов}
Поддержаны операции:
\begin{itemize}
  \item AND: пробел или \texttt{\&\&};
  \item OR: \texttt{||};
  \item NOT: \texttt{!};
  \item скобки: \texttt{( )}.
\end{itemize}
Термы запроса токенизируются по тем же правилам, что и документы: UTF-8, кириллица/латиница/цифры, приведение к нижнему регистру, стемминг.

\subsection{Алгоритм обработки запроса}
Запрос переводится в обратную польскую нотацию (алгоритм shunting-yard) с приоритетами NOT \(>\) AND \(>\) OR. Вычисление выполняется над postings-списками:
\begin{itemize}
  \item AND — пересечение отсортированных списков;
  \item OR — слияние отсортированных списков;
  \item NOT — разность относительно множества всех документов.
\end{itemize}

\subsection{Формирование выдачи}
Для каждого найденного \texttt{doc\_id} извлекаются метаданные (title, page\_id, source), после чего формируется ссылка на источник и выводится результат. Реализована пагинация выдачи через параметры \texttt{offset} и \texttt{limit}. В веб-интерфейсе Streamlit выводятся кликабельные ссылки на документы.

\section{Заключение}
Выполнен полный цикл построения учебной поисковой системы. Сформирован корпус из двух источников MediaWiki, реализован робот обкачки с хранением raw HTML и метаданными в базе данных, выполнены токенизация и стемминг, исследовано распределение частот терминов и закон Ципфа, построен булев индекс и реализован булев поиск с поддержкой AND/OR/NOT и скобок, а также интерфейсом выдачи в CLI и Web.

\end{document}
